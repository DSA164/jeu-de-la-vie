---
# ğŸš€ Calcul matriciel optimisÃ© pour le **Jeu de la vie**

Le **Jeu de la vie de Conway** peut Ãªtre exprimÃ© en **calcul matriciel** pour accÃ©lÃ©rer drastiquement son exÃ©cution.  
Voici les diffÃ©rentes approches possibles, du simple **NumPy** au **GPU**.


---


## 1. ğŸ² ReprÃ©sentation matricielle
On reprÃ©sente la grille comme une **matrice binaire** `A` (numpy array, bool/int8) :  
- `1` â†’ cellule vivante  
- `0` â†’ cellule morte


---


## 2. â• Calcul vectorisÃ© des voisins (`numpy.roll`)

### 2.1. (`numpy.roll`)
Au lieu de boucler cellule par cellule, on additionne les **versions dÃ©calÃ©es** de la matrice :

```python
import numpy as np

def step(A: np.ndarray) -> np.ndarray:
    # Somme des voisins via dÃ©calages (bords pÃ©riodiques)
    N = (
        np.roll(np.roll(A,  1, axis=0),  1, axis=1) +  # haut-gauche
        np.roll(np.roll(A,  1, axis=0),  0, axis=1) +  # haut
        np.roll(np.roll(A,  1, axis=0), -1, axis=1) +  # haut-droit
        np.roll(np.roll(A,  0, axis=0),  1, axis=1) +  # gauche
        np.roll(np.roll(A,  0, axis=0), -1, axis=1) +  # droite
        np.roll(np.roll(A, -1, axis=0),  1, axis=1) +  # bas-gauche
        np.roll(np.roll(A, -1, axis=0),  0, axis=1) +  # bas
        np.roll(np.roll(A, -1, axis=0), -1, axis=1)    # bas-droit
    )

    # RÃ¨gles de Conway (matriciel)
    return ((N == 3) | ((A == 1) & (N == 2))).astype(np.uint8)
```


### 2.2. (`numpy.pad`)
Une alternative consiste Ã  **ajouter un bord artificiel** autour de la grille avec `np.pad`, puis Ã  sommer des tranches.  
Deux modes utiles :  
- `mode="constant", constant_values=0` â†’ bords **non pÃ©riodiques** (extÃ©rieur mort).  
- `mode="wrap"` â†’ bords **pÃ©riodiques** (Ã©quivalent au `roll`).  

```python
import numpy as np

def step_pad(A: np.ndarray, periodic: bool = True) -> np.ndarray:
    mode = "wrap" if periodic else "constant"
    gp = np.pad(A, ((1, 1), (1, 1)), mode=mode)

    # Somme des 8 voisins par tranches (la zone centrale de gp correspond Ã  A)
    N = (
        gp[:-2, :-2] + gp[:-2, 1:-1] + gp[:-2, 2:] +
        gp[1:-1, :-2]                + gp[1:-1, 2:] +
        gp[2:,   :-2] + gp[2:,   1:-1] + gp[2:,   2:]
    )

    # RÃ¨gles de Conway (matriciel)
    return ((N == 3) | ((A == 1) & (N == 2))).astype(np.uint8)
```

**ğŸ“Š Comparaison `np.roll` vs `np.pad`**

- **`np.roll`**  
  - 8 dÃ©calages = **8 copies temporaires** de taille `nÃ—m`.  
  - TrÃ¨s efficace pour des grilles petites/moyennes (`~100Ã—100` Ã  `~500Ã—500`).  
  - Au-delÃ  (`2000Ã—2000` et +), la multiplication des copies augmente le coÃ»t mÃ©moire et CPU.

- **`np.pad` + slicing**  
  - 1 seule copie temporaire de taille `(n+2)Ã—(m+2)`.  
  - Les 8 dÃ©calages sont remplacÃ©s par des **tranches (views)**, trÃ¨s peu coÃ»teuses.  
  - La surcharge de `np.pad` est faible (copie directe en mÃ©moire).  
  - Plus intÃ©ressant pour de **grandes grilles**.

ğŸ‘‰ En rÃ©sumÃ© :  
- **Petites grilles** â†’ `np.roll` (simplicitÃ©, rapiditÃ©).  
- **Grandes grilles** â†’ `np.pad` (Ã©conomie mÃ©moire, plus scalable).  
  - permet aussi la simplification de l'Ã©criture de la fonction `evolution()` pour considÃ©rent les 2 cas de figure: bords limitant et bords pÃ©riodiques

---



## 3. ğŸ›ï¸ Optimisation par convolution

### 3.1. Variante SciPy
On utilise une convolution 2D avec un noyau 3Ã—3 rempli de 1, sauf au centre :
```python
import numpy as np
from scipy.signal import convolve2d

KERNEL = np.array([[1, 1, 1],
                   [1, 0, 1],
                   [1, 1, 1]], dtype=np.uint8)

def step_conv(A: np.ndarray) -> np.ndarray:
    # boundary="wrap" â†’ bords pÃ©riodiques ; mode="same" â†’ conservation de la taille
    N = convolve2d(A, KERNEL, mode="same", boundary="wrap")
    return ((N == 3) | ((A == 1) & (N == 2))).astype(np.uint8)
```

>Atouts :
>`scipy.signal.convolve2d` est implÃ©mentÃ© en C â†’ trÃ¨s rapide.
>Peut utiliser la FFT (selon la taille) pour accÃ©lÃ©rer les grandes grilles.



### 3.2. Convolution via SciPy/ndimage (alternative)
`ndimage.convolve` est optimisÃ©e en C et gÃ¨re aussi les bords pÃ©riodiques.


```python
import numpy as np
from scipy import ndimage as ndi

KERNEL = np.array([[1, 1, 1],
                   [1, 0, 1],
                   [1, 1, 1]], dtype=np.uint8)

def step_conv_ndimage(A: np.ndarray) -> np.ndarray:
    N = ndi.convolve(A, KERNEL, mode="wrap")
    return ((N == 3) | ((A == 1) & (N == 2))).astype(np.uint8)
```



### 3.3. Convolution FFT (utile sur trÃ¨s grandes grilles)
La convolution par FFT devient avantageuse pour des tailles importantes. Avec `scipy.signal.fftconvolve` :

```python
import numpy as np
from scipy.signal import fftconvolve

# MÃªme kernel 3x3 (on peut rester en int, mais la FFT travaille en float)
KERNEL = np.array([[1, 1, 1],
                   [1, 0, 1],
                   [1, 1, 1]], dtype=np.float32)

def step_conv_fft(A: np.ndarray) -> np.ndarray:
    A_f = A.astype(np.float32)
    # 'same' pour conserver la taille ; pour wrap, on peut appliquer un padding circulaire manuel
    N = fftconvolve(A_f, KERNEL, mode="same")
    N = np.rint(N).astype(np.int32)  # remet en entier
    return ((N == 3) | ((A == 1) & (N == 2))).astype(np.uint8)
```

>ğŸ’¡ Pour un vÃ©ritable wrap avec FFT, on peut replier les bords (tiling) avant FFT, ou utiliser des librairies spÃ©cialisÃ©es. Sur de petites grilles, prÃ©fÃ©rez `convolve2d`.



### 3.4. Convolution PyTorch (CPU/GPU)
Utilise les tensors et lâ€™API `conv2d`. Pour un bord pÃ©riodique, on applique un padding circulaire puis une conv sans padding.

```python
import numpy as np
import torch
import torch.nn.functional as F

# SÃ©lection automatique CPU/GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Kernel 3x3 (1â†’vivant, 0â†’mort) sans le centre
KERNEL_T = torch.tensor([[1, 1, 1],
                         [1, 0, 1],
                         [1, 1, 1]], dtype=torch.float32, device=device).view(1, 1, 3, 3)

@torch.no_grad()
def step_conv_torch(A_np: np.ndarray) -> np.ndarray:
    # A_np : (H, W) binaire {0,1}
    A = torch.from_numpy(A_np.astype(np.float32)).to(device).unsqueeze(0).unsqueeze(0)  # (1,1,H,W)

    # Padding circulaire de 1 pixel (gauche/droite/haut/bas)
    A_pad = F.pad(A, pad=(1, 1, 1, 1), mode="circular")

    # Convolution sans padding (dÃ©jÃ  padÃ©e)
    N = F.conv2d(A_pad, KERNEL_T, padding=0)  # (1,1,H,W)

    # RÃ¨gle de Conway (en float/bool tensor)
    alive_next = (N == 3) | ((A == 1) & (N == 2))
    return alive_next.squeeze(0).squeeze(0).to(torch.uint8).cpu().numpy()
```

>âœ… Remplacez device = torch.device("cuda" ...) pour forcer CPU/GPU.
>Avec CUDA, cette version peut Ãªtre trÃ¨s rapide sur de grandes grilles.



### 3.5. Convolution CuPy (GPU NVIDIA, API NumPy-like)
CuPy offre une API compatible NumPy. On peut Ã©galement utiliser cupyx.scipy.signal.convolve2d.

```python
# pip install cupy-cuda12x  (selon votre version CUDA)
import cupy as cp
from cupyx.scipy.signal import convolve2d as cp_convolve2d

KERNEL_CP = cp.array([[1, 1, 1],
                      [1, 0, 1],
                      [1, 1, 1]], dtype=cp.uint8)

def step_conv_cupy(A_np: np.ndarray) -> np.ndarray:
    A = cp.array(A_np, dtype=cp.uint8)
    N = cp_convolve2d(A, KERNEL_CP, mode="same", boundary="wrap")
    next_state = ((N == 3) | ((A == 1) & (N == 2))).astype(cp.uint8)
    return cp.asnumpy(next_state)
```


---



## 4. Note sur les bords (padding/boundary)
 - `wrap` = tore (pÃ©riodique) â†’ recommandÃ© pour animations continues.
 - `reflect` / `symmetric` = effet miroir (peut influencer la dynamique aux bords).
 - `fill` / `constant` = bords morts (peut â€œmangerâ€ les motifs au bord).
   
> Choisissez le mÃªme mode pour toutes vos variantes afin dâ€™obtenir des rÃ©sultats identiques entre implÃ©mentations.


---



## 5. Mini-benchmark (sanity check + timing)
Exemple rapide pour vÃ©rifier la cohÃ©rence entre deux implÃ©mentations et comparer les temps (CPU).
âš ï¸ Ajustez la taille H, W et le nombre dâ€™itÃ©rations selon votre machine.


```python
import numpy as np
import time

# Exemple : comparer step_conv (SciPy) vs step (np.roll)
H, W = 1024, 1024
A0 = (np.random.rand(H, W) > 0.8).astype(np.uint8)

# --- Sanity check (1 step) ---
A_roll = step(A0)           # depuis la section 2
A_scipy = step_conv(A0)     # 3.1

print("Identiques ?", np.array_equal(A_roll, A_scipy))

# --- Timing ---
def timeit(fn, A, n=50):
    A_ = A.copy()
    t0 = time.perf_counter()
    for _ in range(n):
        A_ = fn(A_)
    return time.perf_counter() - t0

t_roll = timeit(step, A0, n=50)
t_scipy = timeit(step_conv, A0, n=50)

print(f"np.roll: {t_roll:.3f}s  |  scipy.convolve2d: {t_scipy:.3f}s")
```

>ğŸ’¡ Sur grandes grilles, `scipy.signal.convolve2d` ou **PyTorch/CuPy** (GPU) dominent gÃ©nÃ©ralement `np.roll`.
