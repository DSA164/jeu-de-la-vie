---
# ðŸš€ Calcul matriciel optimisÃ© pour le **Jeu de la vie**

Le **Jeu de la vie de Conway** peut Ãªtre exprimÃ© en **calcul matriciel** pour accÃ©lÃ©rer drastiquement son exÃ©cution.  
Voici les diffÃ©rentes approches possibles, du simple **NumPy** au **GPU**.

---

## 1. ðŸŽ² ReprÃ©sentation matricielle
On reprÃ©sente la grille comme une **matrice binaire** `A` (numpy array, bool/int8) :  
- `1` â†’ cellule vivante  
- `0` â†’ cellule morte

> â„¹ï¸ Les exemples ci-dessous utilisent des **bords pÃ©riodiques** (â€œtoreâ€).  

---

## 2. âž• Calcul vectorisÃ© des voisins (`numpy.roll`)
Au lieu de boucler cellule par cellule, on additionne les **versions dÃ©calÃ©es** de la matrice :

```python
import numpy as np

def step(A: np.ndarray) -> np.ndarray:
    # Somme des voisins via dÃ©calages (bords pÃ©riodiques)
    N = (
        np.roll(np.roll(A,  1, axis=0),  1, axis=1) +  # haut-gauche
        np.roll(np.roll(A,  1, axis=0),  0, axis=1) +  # haut
        np.roll(np.roll(A,  1, axis=0), -1, axis=1) +  # haut-droit
        np.roll(np.roll(A,  0, axis=0),  1, axis=1) +  # gauche
        np.roll(np.roll(A,  0, axis=0), -1, axis=1) +  # droite
        np.roll(np.roll(A, -1, axis=0),  1, axis=1) +  # bas-gauche
        np.roll(np.roll(A, -1, axis=0),  0, axis=1) +  # bas
        np.roll(np.roll(A, -1, axis=0), -1, axis=1)    # bas-droit
    )

    # RÃ¨gles de Conway (matriciel)
    return ((N == 3) | ((A == 1) & (N == 2))).astype(np.uint8)
```

---

## 3. ðŸŽ›ï¸ Optimisation par convolution

### 3.1. Variante SciPy
On utilise une convolution 2D avec un noyau 3Ã—3 rempli de 1, sauf au centre :
```python
import numpy as np
from scipy.signal import convolve2d

KERNEL = np.array([[1, 1, 1],
                   [1, 0, 1],
                   [1, 1, 1]], dtype=np.uint8)

def step_conv(A: np.ndarray) -> np.ndarray:
    # boundary="wrap" â†’ bords pÃ©riodiques ; mode="same" â†’ conservation de la taille
    N = convolve2d(A, KERNEL, mode="same", boundary="wrap")
    return ((N == 3) | ((A == 1) & (N == 2))).astype(np.uint8)
```
Atouts :
`scipy.signal.convolve2d` est implÃ©mentÃ© en C â†’ trÃ¨s rapide.
Peut utiliser la FFT (selon la taille) pour accÃ©lÃ©rer les grandes grilles.

### 3.2. Convolution via SciPy/ndimage (alternative)
`ndimage.convolve` est optimisÃ©e en C et gÃ¨re aussi les bords pÃ©riodiques.

```python
```

```python
import numpy as np
from scipy import ndimage as ndi

KERNEL = np.array([[1, 1, 1],
                   [1, 0, 1],
                   [1, 1, 1]], dtype=np.uint8)

def step_conv_ndimage(A: np.ndarray) -> np.ndarray:
    N = ndi.convolve(A, KERNEL, mode="wrap")
    return ((N == 3) | ((A == 1) & (N == 2))).astype(np.uint8)
```

### 3.3. Convolution FFT (utile sur trÃ¨s grandes grilles)
La convolution par FFT devient avantageuse pour des tailles importantes. Avec `scipy.signal.fftconvolve` :

```python
import numpy as np
from scipy.signal import fftconvolve

# MÃªme kernel 3x3 (on peut rester en int, mais la FFT travaille en float)
KERNEL = np.array([[1, 1, 1],
                   [1, 0, 1],
                   [1, 1, 1]], dtype=np.float32)

def step_conv_fft(A: np.ndarray) -> np.ndarray:
    A_f = A.astype(np.float32)
    # 'same' pour conserver la taille ; pour wrap, on peut appliquer un padding circulaire manuel
    N = fftconvolve(A_f, KERNEL, mode="same")
    N = np.rint(N).astype(np.int32)  # remet en entier
    return ((N == 3) | ((A == 1) & (N == 2))).astype(np.uint8)
```


ðŸ’¡ Pour un vÃ©ritable wrap avec FFT, on peut replier les bords (tiling) avant FFT, ou utiliser des librairies spÃ©cialisÃ©es. Sur de petites grilles, prÃ©fÃ©rez `convolve2d`.

### 3.4. Convolution PyTorch (CPU/GPU)
Utilise les tensors et lâ€™API `conv2d`. Pour un bord pÃ©riodique, on applique un padding circulaire puis une conv sans padding.

```python
import numpy as np
import torch
import torch.nn.functional as F

# SÃ©lection automatique CPU/GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Kernel 3x3 (1â†’vivant, 0â†’mort) sans le centre
KERNEL_T = torch.tensor([[1, 1, 1],
                         [1, 0, 1],
                         [1, 1, 1]], dtype=torch.float32, device=device).view(1, 1, 3, 3)

@torch.no_grad()
def step_conv_torch(A_np: np.ndarray) -> np.ndarray:
    # A_np : (H, W) binaire {0,1}
    A = torch.from_numpy(A_np.astype(np.float32)).to(device).unsqueeze(0).unsqueeze(0)  # (1,1,H,W)

    # Padding circulaire de 1 pixel (gauche/droite/haut/bas)
    A_pad = F.pad(A, pad=(1, 1, 1, 1), mode="circular")

    # Convolution sans padding (dÃ©jÃ  padÃ©e)
    N = F.conv2d(A_pad, KERNEL_T, padding=0)  # (1,1,H,W)

    # RÃ¨gle de Conway (en float/bool tensor)
    alive_next = (N == 3) | ((A == 1) & (N == 2))
    return alive_next.squeeze(0).squeeze(0).to(torch.uint8).cpu().numpy()
```

âœ… Remplacez device = torch.device("cuda" ...) pour forcer CPU/GPU.
Avec CUDA, cette version peut Ãªtre trÃ¨s rapide sur de grandes grilles.

### 3.5. Convolution CuPy (GPU NVIDIA, API NumPy-like)
CuPy offre une API compatible NumPy. On peut Ã©galement utiliser cupyx.scipy.signal.convolve2d.

```python
# pip install cupy-cuda12x  (selon votre version CUDA)
import cupy as cp
from cupyx.scipy.signal import convolve2d as cp_convolve2d

KERNEL_CP = cp.array([[1, 1, 1],
                      [1, 0, 1],
                      [1, 1, 1]], dtype=cp.uint8)

def step_conv_cupy(A_np: np.ndarray) -> np.ndarray:
    A = cp.array(A_np, dtype=cp.uint8)
    N = cp_convolve2d(A, KERNEL_CP, mode="same", boundary="wrap")
    next_state = ((N == 3) | ((A == 1) & (N == 2))).astype(cp.uint8)
    return cp.asnumpy(next_state)


```
